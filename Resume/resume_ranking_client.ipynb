{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "251d4d88-2f03-491b-963d-d169c6978542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports and Setup\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.corpus import wordnet, stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Uncomment the following line if you need to download the NLTK data\n",
    "# nltk.download('all')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "577bd2bd-24a1-415e-b74e-c68c6aec4e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Data Loading and Preprocessing\n",
    "data = pd.read_csv('Resume Ranking Data set.csv')\n",
    "data_copy = data.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8665dbdf-d623-475d-967a-a1747c70444d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "columns_to_drop = ['accomplishments_segment', 'education_segment', 'emails', 'misc_segment', 'name', \n",
    "                   'objectives_segment', 'phone', 'projects_segment', 'skills_segment', 'text', \n",
    "                   'university_0', 'university_1', 'university_2', 'university_3', \n",
    "                   'university_4', 'university_5', 'url', 'work_segment']\n",
    "data.drop(columns=columns_to_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d0fa7aa0-c869-4041-8037-6d41d9e88e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values without using inplace=True\n",
    "data['degree'] = data['degree'].fillna(data.degree.mode()[0])\n",
    "data['links'] = data['links'].fillna('Missing')\n",
    "data['work_experience'] = data['work_experience'].fillna(0)\n",
    "data['job_titles'] = data['job_titles'].fillna('No Job')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c287b1cd-f2ce-4a1b-ae40-668527434ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract unique degrees\n",
    "all_degrees = ','.join(data.degree.dropna().tolist())\n",
    "all_degrees = [re.sub(r\"[\\s.]\", \"\", degree).upper() for degree in all_degrees.split(',')]\n",
    "unique_degrees = set(all_degrees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b2f6eb22-9ac2-47ad-86c3-f76954392108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize new columns\n",
    "data['bachelor_degrees'] = 'No Degree'\n",
    "data['master_degrees'] = 'No Degree'\n",
    "data['doctorate_degrees'] = 'No Degree'\n",
    "data['profiles'] = 'No Profile'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8a742697-c5a8-4cb9-a692-95e3f4947118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Degree and Profile Classification\n",
    "def classify_degrees(row):\n",
    "    degrees = re.sub(r\"[\\s.]\", \"\", row['degree']).upper().split(',')\n",
    "    for degree in degrees:\n",
    "        if degree in ['BE', 'BS', 'BSC', 'BTECH']:\n",
    "            row['bachelor_degrees'] = degree if row['bachelor_degrees'] == 'No Degree' else row['bachelor_degrees'] + ' , ' + degree\n",
    "        elif degree in ['ME', 'MS', 'MSC', 'MTECH']:\n",
    "            row['master_degrees'] = degree if row['master_degrees'] == 'No Degree' else row['master_degrees'] + ' , ' + degree\n",
    "        elif degree == 'PHD':\n",
    "            row['doctorate_degrees'] = degree if row['doctorate_degrees'] == 'No Degree' else row['doctorate_degrees'] + ' , ' + degree\n",
    "    return row\n",
    "\n",
    "data = data.apply(classify_degrees, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "53ef4c69-1468-469f-ba0e-a97edf94b5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_profiles(row):\n",
    "    links = re.sub(r\"[\\s]\", \"\", row['links']).split(',')\n",
    "    for link in links:\n",
    "        if 'github' in link:\n",
    "            row['profiles'] = 'Github'\n",
    "        elif 'linkedin' in link:\n",
    "            row['profiles'] = 'Linkedin' if row['profiles'] == 'No Profile' else row['profiles'] + ' , ' + 'Linkedin'\n",
    "    return row\n",
    "\n",
    "data = data.apply(classify_profiles, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "dc50f246-fce5-483a-92be-55d741e6c376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns after processing\n",
    "data.drop(['degree', 'links'], axis=1, inplace=True)\n",
    "\n",
    "# Cell 4: Lemmatization and TF-IDF Cosine Similarity\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "analyzer = CountVectorizer().build_analyzer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ef4dde6f-7593-46f5-83d0-2fb5732f67b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatized_words(doc):\n",
    "    doc = doc.lower()\n",
    "    return [lemmatizer.lemmatize(word, get_wordnet_pos(word)) for word in analyzer(doc) if word not in set(stopwords.words('english'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "73ab4fce-4c62-48b1-a85a-9f046575d05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(word):\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ, \"N\": wordnet.NOUN, \"V\": wordnet.VERB, \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1a2ae956-0c63-4f44-849d-383e9170608e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def compute_tf_idf_cosine_similarity(job_desc, resumes):\n",
    "    tf_idf_vectorizer = TfidfVectorizer(analyzer=lemmatized_words,lowercase=True)\n",
    "    tf_idf_job_desc_vector = tf_idf_vectorizer.fit_transform(np.asarray([job_description]))\n",
    "    tf_idf_resume_vectors = tf_idf_vectorizer.transform(resumes).todense()\n",
    "    return [cosine_similarity(tf_idf_job_desc_vector, tf_idf_resume_vectors[i])[0][0] for i in range(len(tf_idf_resume_vectors))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a37cf5-1579-4228-9a45-4997a23558f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load job description\n",
    "with open('Job Description.txt', 'r', encoding='utf-8') as f:\n",
    "    job_description = ' '.join([line.strip() for line in f])\n",
    "\n",
    "# Prepare resume text data\n",
    "resume_texts = data_copy['text'].values\n",
    "\n",
    "# Define and fit TF-IDF vectorizer\n",
    "vectorizer = LemmaTfidfVectorizer(lowercase=True)\n",
    "job_desc_vector = vectorizer.fit_transform([job_description])\n",
    "resume_vectors = vectorizer.transform(resume_texts)\n",
    "\n",
    "# Calculate cosine similarities\n",
    "cosine_similarities = [cosine_similarity(job_desc_vector, resume_vector)[0][0] for resume_vector in resume_vectors]\n",
    "\n",
    "# Zip and sort resume ratings\n",
    "zipped_resume_ratings = zip(cosine_similarities, data_copy['name'], range(len(data)))\n",
    "sorted_resume_ratings = sorted(zipped_resume_ratings, key=lambda x: x[0], reverse=True)\n",
    "\n",
    "# Display sorted resume ratings\n",
    "sorted_resume_ratings_df = pd.DataFrame(sorted_resume_ratings, columns=['Cosine Similarity', 'Name', 'Index'])\n",
    "sorted_resume_ratings_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b340c769-3f5e-4aa7-bd41-9229099e98cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      name  resume_score(%)\n",
      "0             Prasad Nagar            46.88\n",
      "1        Software Engineer            53.57\n",
      "2        Ashwin Khandelwal            49.79\n",
      "3     Computer Engineering            60.64\n",
      "4                Python            44.27\n",
      "...                    ...              ...\n",
      "1568          Gaurav Arora            35.27\n",
      "1569         Ayokunle Paul            33.46\n",
      "1570       DevOps Engineer            54.32\n",
      "1571        Udaya SaiKiran            42.44\n",
      "1572             D. Shinde            39.39\n",
      "\n",
      "[1573 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Result Display\n",
    "# Compute resume scores\n",
    "resume_scores = [round(score * 100, 2) for score in cosine_similarities]\n",
    "result_df = pd.concat([data_copy.name, pd.DataFrame(resume_scores, columns=['resume_score(%)'])], axis=1)\n",
    "\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4492a528-9068-4972-8821-a2666d63d2a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
